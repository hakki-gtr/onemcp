handbook:
  location: ${env:HANDBOOK_DIR:-classpath:acme-handbook}

prompt:
  location: classpath:prompts

# Logging levels can be configured here and applied at startup by OneMcp
logging:
  level:
    root: INFO
    # Fineâ€‘tune specific packages/classes as needed
    com:
      google:
        genai: OFF
      gentoro:
        onemcp: INFO
    org:
      eclipse:
        jetty: WARN
    okhttp3: INFO
    io:
      modelcontextprotocol: INFO

http:
  port: 8080
  hostname: 0.0.0.0
  acme:
    context-path: /acme
  mcp:
    endpoint: ${env:PROTOCOL_MCP_CONFIG_MESSAGE_ENDPOINT:-/mcp}
    keep-alive: -1
    keep-alive-seconds: -1
    disallow-delete: false
    server:
      name: "onemcp-server"
      version: "1.0.0"
    tool:
      name: onemcp.run
      description: |
        OneMCP entry point, express your request using Natural Language.


llm:
  active-profile: '${sys:llm.active-profile:-gemini-flash}'
  ollama:
    baseUrl: http://192.168.2.77:11434
    model: qwen3-coder:30b
    provider: ollama
  openai:
    apiKey: ${env:OPENAI_API_KEY:-sk-proj-...}
    model: ${env:OPENAI_MODEL_NAME:-gpt-5-nano-2025-08-07}
    provider: openai
  anthropic-sonnet:
    apiKey: ${env:ANTHROPIC_API_KEY:-sk-ant-...}
    model: ${env:ANTHROPIC_MODEL_NAME:-claude-sonnet-4-5-20250929}
    provider: anthropic
  gemini-flash:
    apiKey: ${env:GEMINI_API_KEY:-...}
    model: ${env:GEMINI_MODEL_NAME:-gemini-2.5-flash-lite}
    provider: gemini
  gemini-pro:
    apiKey: ${env:GEMINI_API_KEY:-...}
    model: ${env:GEMINI_MODEL_NAME:-gemini-2.5-pro}
    provider: gemini
  cache:
    enabled: false
